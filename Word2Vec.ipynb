{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b80387ad",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0113bb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import os\n",
    "import io\n",
    "import datetime\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Embedding, Input, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import losses, optimizers\n",
    "from tensorflow.keras.activations import softmax\n",
    "\n",
    "from itertools import islice\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9d927f",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c09c6622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------Head------------------\n",
      "   Unnamed: 0     id                                              title  \\\n",
      "0           0  17283  House Republicans Fret About Winning Their Hea...   \n",
      "1           1  17284  Rift Between Officers and Residents as Killing...   \n",
      "2           2  17285  Tyrus Wong, ‘Bambi’ Artist Thwarted by Racial ...   \n",
      "3           3  17286  Among Deaths in 2016, a Heavy Toll in Pop Musi...   \n",
      "4           4  17287  Kim Jong-un Says North Korea Is Preparing to T...   \n",
      "\n",
      "      publication                         author        date    year  month  \\\n",
      "0  New York Times                     Carl Hulse  2016-12-31  2016.0   12.0   \n",
      "1  New York Times  Benjamin Mueller and Al Baker  2017-06-19  2017.0    6.0   \n",
      "2  New York Times                   Margalit Fox  2017-01-06  2017.0    1.0   \n",
      "3  New York Times               William McDonald  2017-04-10  2017.0    4.0   \n",
      "4  New York Times                  Choe Sang-Hun  2017-01-02  2017.0    1.0   \n",
      "\n",
      "   url                                            content  \n",
      "0  NaN  WASHINGTON  —   Congressional Republicans have...  \n",
      "1  NaN  After the bullet shells get counted, the blood...  \n",
      "2  NaN  When Walt Disney’s “Bambi” opened in 1942, cri...  \n",
      "3  NaN  Death may be the great equalizer, but it isn’t...  \n",
      "4  NaN  SEOUL, South Korea  —   North Korea’s leader, ...  \n",
      "------------------Tail------------------\n",
      "       Unnamed: 0     id                                              title  \\\n",
      "49995       53287  73465   Rex Tillerson Says Climate Change Is Real, but …   \n",
      "49996       53288  73466  The Biggest Intelligence Questions Raised by t...   \n",
      "49997       53289  73467  Trump Announces Plan That Does Little to Resol...   \n",
      "49998       53290  73468    Dozens of For-Profit Colleges Could Soon Close    \n",
      "49999       53291  73469                       The Milky Way’s Stolen Stars   \n",
      "\n",
      "      publication          author        date    year  month  url  \\\n",
      "49995    Atlantic  Robinson Meyer  2017-01-11  2017.0    1.0  NaN   \n",
      "49996    Atlantic      Amy Zegart  2017-01-11  2017.0    1.0  NaN   \n",
      "49997    Atlantic   Jeremy Venook  2017-01-11  2017.0    1.0  NaN   \n",
      "49998    Atlantic     Emily DeRuy  2017-01-11  2017.0    1.0  NaN   \n",
      "49999    Atlantic    Marina Koren  2017-01-11  2017.0    1.0  NaN   \n",
      "\n",
      "                                                 content  \n",
      "49995  As chairman and CEO of ExxonMobil, Rex Tillers...  \n",
      "49996  I’ve spent nearly 20 years looking at intellig...  \n",
      "49997    Donald Trump will not be taking necessary st...  \n",
      "49998  Dozens of   colleges could be forced to close ...  \n",
      "49999  The force of gravity can be described using a ...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('articles1.csv')\n",
    "print('------------------Head------------------')\n",
    "print(df.head())\n",
    "print('------------------Tail------------------')\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795dbd54",
   "metadata": {},
   "source": [
    "# Setting Constraints for Filtering the Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc946361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set `data_limit` zero (0) for processing all of the data.\n",
    "data_limit = 3000\n",
    "# If the fruquency count of a word is less than the `min_frquency_of_word` than it will be removed from the dictionary\n",
    "min_frquency_of_word = 300 \n",
    "window_size = 7\n",
    "max_sentence_lenght = 1000\n",
    "max_word_count = 100\n",
    "min_word_count = 5\n",
    "max_sentence = 1000\n",
    "\n",
    "data_info = {}\n",
    "data_info['data_limit']= data_limit\n",
    "data_info['min_frquency_of_word'] = min_frquency_of_word\n",
    "data_info['window_size'] = window_size \n",
    "data_info['max_sentence_lenght'] = max_sentence_lenght\n",
    "data_info['max_word_count'] = max_word_count \n",
    "data_info['min_word_count'] = min_word_count\n",
    "data_info['max_sentence'] = max_sentence "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a027071",
   "metadata": {},
   "outputs": [],
   "source": [
    "section_texts = df['content'].apply(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffda0c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6f4f6a8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total texts-----> 3000\n"
     ]
    }
   ],
   "source": [
    "if data_limit != 0:\n",
    "    section_texts = section_texts[:data_limit]\n",
    "print('Total texts----->', len(section_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01f28371",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_limit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dace7cd0",
   "metadata": {},
   "source": [
    "### Downloading `nltk` Resources for Data Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67bc505d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ruman/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/ruman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7340200",
   "metadata": {},
   "source": [
    "### Converting Texts to Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c779773b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for texts in section_texts:\n",
    "    for sentence in sent_tokenize(texts):\n",
    "        if len(sentence) < max_sentence_lenght:\n",
    "            sentences.append(sentence.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a62ec2df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences 163768\n"
     ]
    }
   ],
   "source": [
    "total_sentences = len(sentences)\n",
    "print('Total sentences', total_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64a56a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "del texts\n",
    "del section_texts\n",
    "del max_sentence_lenght\n",
    "del sent_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929d56d9",
   "metadata": {},
   "source": [
    "### Filtering out the Sentences, Converting Sentences to Words and Creating Vocabulary with Frequency\n",
    "\n",
    "For filtering out-\n",
    "<ul>\n",
    "  <li>Remove the <b>stop words</b>.</li>\n",
    "  <li>Remove the word if it is not an <b>alpha</b>.</li>\n",
    "  <li>Remove the word if number of character is less than <b>one</b>.</li>\n",
    "  <li>Remove sentences if word count is greater than <b>max_word_count</b> or less than <b>min_word_count</b></li>    \n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c794f606",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "word_list = []\n",
    "vocabulary_with_frequency = {}\n",
    "\n",
    "for sentence in sentences:\n",
    "    words = word_tokenize(sentence)\n",
    "    words_without_stop_words = [word for word in words if word.isalpha() and word not in stop_words and len(word) != 1]\n",
    "    \n",
    "    word_lenght = len(words_without_stop_words)\n",
    "    if word_lenght <= max_word_count and word_lenght >= min_word_count:\n",
    "        word_list.append(words_without_stop_words)\n",
    "        \n",
    "        for word in words_without_stop_words:\n",
    "            if word not in vocabulary_with_frequency.keys():\n",
    "                vocabulary_with_frequency[word] = 1\n",
    "            else:\n",
    "                vocabulary_with_frequency[word] += 1\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be6b93cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60919\n"
     ]
    }
   ],
   "source": [
    "print(len(vocabulary_with_frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4477cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "del stop_words\n",
    "del stopwords\n",
    "del sentences\n",
    "del sentence\n",
    "del words\n",
    "del words_without_stop_words\n",
    "del word_lenght\n",
    "del word\n",
    "del max_sentence\n",
    "del max_word_count\n",
    "del nltk\n",
    "del word_tokenize\n",
    "del total_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0015c0bd",
   "metadata": {},
   "source": [
    "#### Total Words and Vocabularies After Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c459fec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in corpus 1762061\n",
      "Vocabulary size 60919\n"
     ]
    }
   ],
   "source": [
    "total_sentences = len(word_list)\n",
    "\n",
    "total_words = 0\n",
    "for words in word_list:\n",
    "    total_words += len(words)\n",
    "print('Total words in corpus', total_words)\n",
    "print('Vocabulary size', len(vocabulary_with_frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af2cc722",
   "metadata": {},
   "outputs": [],
   "source": [
    "del words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcf64ad",
   "metadata": {},
   "source": [
    "### Sorting Vocabulary Based on Frequency Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebb1bcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_vocabulary_with_frequency = sorted(vocabulary_with_frequency.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df438285",
   "metadata": {},
   "source": [
    "### Removing the Word Form the Dictioary if Frequency count is Less Than `min_frquency_of_word`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6da80de",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_vocabulary = {key: frequency for key, frequency in sorted_vocabulary_with_frequency if frequency > min_frquency_of_word}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f61f269",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sorted_vocabulary_with_frequency\n",
    "del vocabulary_with_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450b6cc6",
   "metadata": {},
   "source": [
    "### Removing the Less Freuquent Word form Dictionary and Assigning Unique Id to Each Word\n",
    "\n",
    "Also created two dictionaries-\n",
    "<ul>\n",
    "  <li><b>word_to_id:</b> to get word for a word id.</li>\n",
    "  <li><b>id_to_word:</b> to get the id for word.</li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2588df39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 'PAD'), ('said', 1), ('trump', 2), ('would', 3), ('one', 4), ('new', 5), ('people', 6), ('president', 7), ('like', 8), ('also', 9), ('could', 10), ('years', 11), ('states', 12), ('last', 13), ('united', 14)]\n",
      "-------------------------------------\n",
      "[('PAD', 0), (1, 'said'), (2, 'trump'), (3, 'would'), (4, 'one'), (5, 'new'), (6, 'people'), (7, 'president'), (8, 'like'), (9, 'also'), (10, 'could'), (11, 'years'), (12, 'states'), (13, 'last'), (14, 'united')]\n"
     ]
    }
   ],
   "source": [
    "word_to_id = {}\n",
    "word_to_id[0] = 'PAD'\n",
    "id_to_word = {}\n",
    "id_to_word['PAD'] = 0\n",
    "word_id = 1\n",
    "\n",
    "for word in sorted_vocabulary:\n",
    "    word_to_id[word] = word_id\n",
    "    id_to_word[word_id] = word\n",
    "    word_id += 1\n",
    "print(list(islice(word_to_id.items(), 15)))\n",
    "print('-------------------------------------')\n",
    "print(list(islice(id_to_word.items(), 15)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8c6584aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "del sorted_vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b3b870",
   "metadata": {},
   "source": [
    "### Converting `word_list` to `word_id_list` for Expressign the Words by Unique Dincatioanry ID  \n",
    "In this step I have also--\n",
    "<ul>\n",
    "  <li>Removed a word if that is not in the dictionary</li>\n",
    "  <li>Removed a sentece if word count is less than the <b>min_word_count</b></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dcb0dbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences before filtering 135022\n",
      "Total words before filtering 1762061\n"
     ]
    }
   ],
   "source": [
    "data_info['Total sentences before filtering'] = total_sentences\n",
    "data_info['Total words before filtering'] = total_words\n",
    "\n",
    "print('Total sentences before filtering', total_sentences)\n",
    "print('Total words before filtering', total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c02693f0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------\n",
      "Total sentences after filtering 91451\n",
      "Total words after filtering 787833\n"
     ]
    }
   ],
   "source": [
    "sentece_word_ids = []\n",
    "total_sentences = 0\n",
    "total_words = 0\n",
    "\n",
    "for words in word_list:\n",
    "    filtered_words_ids = [word_to_id[word] for word in words if word in word_to_id.keys()]\n",
    "    words_in_current_sentece = len(filtered_words_ids)\n",
    "    \n",
    "    if words_in_current_sentece >= min_word_count:\n",
    "        total_sentences += 1\n",
    "        total_words += words_in_current_sentece\n",
    "        sentece_word_ids.append(filtered_words_ids)\n",
    "        \n",
    "print('--------------------------------------------')\n",
    "print('Total sentences after filtering', total_sentences)\n",
    "print('Total words after filtering', total_words)\n",
    "\n",
    "data_info['Total sentences after filtering'] = total_sentences\n",
    "data_info['Total words after filtering'] = total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35015a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "del words\n",
    "del word_list\n",
    "del min_word_count                     \n",
    "del word_id  \n",
    "del filtered_words_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211b3a88",
   "metadata": {},
   "source": [
    "## Untill Now \n",
    "<br> \n",
    "<b>sentece_word_ids:</b> Sentence wise word's id. <br>\n",
    "<b>word_to_id:</b> Dictionary for getting the <b>word_id</b> for a <b>word</b>.<br>\n",
    "<b>id_to_word:</b> Dictionary for getting the <b>word</b> for a <b> word_id</b>.<br>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da05f647",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sentences 91451\n",
      "Total words 787833\n",
      "Total unique words in dictionary 1102\n"
     ]
    }
   ],
   "source": [
    "print('Total sentences', total_sentences)\n",
    "print('Total words', total_words)\n",
    "vocabulary_size = len(word_to_id)\n",
    "print('Total unique words in dictionary', vocabulary_size)\n",
    "data_info['Total unique words in dictionary'] = vocabulary_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db4165c",
   "metadata": {},
   "source": [
    "### Loading the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adc2d5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a985fc",
   "metadata": {},
   "source": [
    "### Helper Function for Saving and Loading the Model, Informatino\n",
    "\n",
    "In every cases name will be `skip` for skip-gram model and `cbow` for CBOW model.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "abf604e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_path_name(name):\n",
    "    if name == 'pair':\n",
    "        return 'save/model_pair/'\n",
    "    elif name == 'skip':\n",
    "        return 'save/model_skip/'\n",
    "    elif name == 'cbow':\n",
    "        return 'save/model_cbow/'\n",
    "    \n",
    "def get_unique_file_name():\n",
    "    return datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S-%f\")\n",
    "\n",
    "\n",
    "def save_model(name, model, file_name):\n",
    "    path = get_path_name(name)+'model/'\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "    if name == 'cbow':\n",
    "        model.save(path+file_name+'/')\n",
    "    else:\n",
    "         model.save(path+file_name+'.h5')\n",
    "            \n",
    "            \n",
    "def load_model(name, file_name):\n",
    "    path = get_path_name(name)+'model/'\n",
    "    \n",
    "    if name == 'cbow':\n",
    "        return keras.models.load_model(\n",
    "            os.getcwd()+'/'+path+'/'+file_name+'/', custom_objects={\"Average\": Average, \"custom_loss_function\": custom_loss_function}\n",
    "        )\n",
    "    \n",
    "    return tf.keras.models.load_model(path+file_name+'.h5', custom_objects={\"custom_loss_function\": custom_loss_function})\n",
    "\n",
    "\n",
    "def get_model_list(name):\n",
    "    path = get_path_name(name)+'model/'\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        return os.listdir(path)\n",
    "    \n",
    "def save_info(name, file_name, data):\n",
    "    path = get_path_name(name)+'data_info/'\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "            \n",
    "    with open(path+file_name+'.yaml', 'w') as file:\n",
    "        documents = yaml.dump(data, file, sort_keys=False)\n",
    "    \n",
    "    \n",
    "def get_info_list(name):\n",
    "    path = get_path_name(name)+'data_info/'\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "        return os.listdir(path)\n",
    "        \n",
    "\n",
    "def get_info(name, file_name):\n",
    "    path = get_path_name(name)+'data_info/'\n",
    "    \n",
    "    if os.path.exists(path):\n",
    "            with open(path+file_name+'.yaml') as file:\n",
    "                return yaml.load(file, Loader=yaml.Loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08e575df",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = get_unique_file_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "929921f9",
   "metadata": {},
   "source": [
    "### Generate 2D `vocabulary_size` List for Getting the `one-hot` Vector for a Word Id\n",
    "\n",
    "`one_hot` will work as a `lookup table` to get one-hot encoded vector for a `word_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7eb90fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = np.zeros((vocabulary_size,vocabulary_size))\n",
    "\n",
    "for index in range(1, vocabulary_size):\n",
    "    one_hot[index][index] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4465d45",
   "metadata": {},
   "source": [
    "# Processing Data for the CBOW and SKIP-GRAM Model\n",
    "\n",
    "In `CBOW` and `SKIP-GRAM` models, will be needed the one-hot encoded `target word` and their corresponding one-hot encoded `context words`. And the size of the one-hot encoded vector will be `vocabulary_size`. \n",
    "\n",
    "One-hot encoded `target_id` and `context_ids` creating process. \n",
    "\n",
    "---<b>target_id: </b>Created a zeros vector of `vocabulary_size`. Then simply assigned the value `one(1)` to an index of the vector, if index number is equal to the `word_id`<br>\n",
    "---<b>context_ids:</b> Created total `window_size * 2`(maximum) `context_ids` for a `word_id`. Then I have created one-hot vector for `context_ids`, using the similar way I have created one-hot vector for a `target_id`. Additionaly, I have also sum up all of the one-hot encoded `context_ids` vectors to a single one-hot encoded vector of size `vocabulary_size`. So, there is one vector of size `vocabulary_size`, for containing all of the `context_ids` of a `target_id`. Because in `CBOW` model, at input layer and in `skip-gram` model at output layer, I have to sum up the one-hot context vectors. Here I have precalcualted it here.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d003cf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_contexts(word_ids, window_size):\n",
    "    target_id = []\n",
    "    context_ids = []\n",
    "    \n",
    "    for ids in word_ids:\n",
    "        for index, word_id in enumerate(ids):\n",
    "            if not word_id:\n",
    "                continue\n",
    "                \n",
    "            window_start = max(0, index - window_size)\n",
    "            window_end = min(len(ids), index + window_size + 1)\n",
    "            \n",
    "            target_id.append(one_hot[word_id])\n",
    "            \n",
    "            zero_context_ids = np.zeros(vocabulary_size)\n",
    "            for window_index in range(window_start, window_end):\n",
    "                if window_index != index:\n",
    "                    zero_context_ids[ids[window_index]] += 1\n",
    "            context_ids.append(zero_context_ids)\n",
    "            del zero_context_ids\n",
    "            \n",
    "    return target_id, context_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0901db46",
   "metadata": {},
   "outputs": [],
   "source": [
    "del index                      \n",
    "del min_frquency_of_word       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "01d545b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_id, context_ids =  get_target_contexts(sentece_word_ids, window_size)\n",
    "data_info['Total target words'] = len(target_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910532d8",
   "metadata": {},
   "source": [
    "### Splitting the Training and Testing Data. Taking 20% Data for Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ad66e205",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_target_list, X_test_target_list, Y_train_contexts_list, Y_test_contexts_list = train_test_split(target_id, context_ids, test_size=0.2, random_state=42)\n",
    "del target_id\n",
    "del context_ids\n",
    "Train_target = np.array(X_train_target_list, dtype=np.float16)\n",
    "del X_train_target_list\n",
    "Test_target = np.array(X_test_target_list, dtype=np.float16)\n",
    "del X_test_target_list\n",
    "Train_contexts = np.array(Y_train_contexts_list, dtype=np.float16)\n",
    "del Y_train_contexts_list\n",
    "Test_contexts = np.array(Y_test_contexts_list, dtype=np.float16)\n",
    "del Y_test_contexts_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fff14e2",
   "metadata": {},
   "source": [
    "# CBOW Model\n",
    "\n",
    "In `CBOW` model our input will be the vector of `context_ids` to predict the `target_id`. So, `Train_contexts` will be our input and the target will be `Train_target`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a29a8139",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info_cbow =  data_info.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0a9814",
   "metadata": {},
   "source": [
    "### Extending Keras Layer for Taking the Average of Embeddings Layer\n",
    "\n",
    "I have alredys sum up of the input vectors. So, in this layer I've just taking the average after multiplying the the input vector with weight matrix(input layer). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d96af11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Average(keras.layers.Layer):\n",
    "    def __init__(self, units=32, input_dim=32):\n",
    "        super(Average, self).__init__()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.math.divide(inputs, window_size*2)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91cd754",
   "metadata": {},
   "source": [
    "### Building the model for CBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a15ab51b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1102)]            0         \n",
      "_________________________________________________________________\n",
      "w2v_embedding_cbow (Dense)   (None, 350)               386050    \n",
      "_________________________________________________________________\n",
      "average (Average)            (None, 350)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1102)              386802    \n",
      "=================================================================\n",
      "Total params: 772,852\n",
      "Trainable params: 772,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 04:07:17.464921: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2021-11-25 04:07:17.465100: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(vocabulary_size, ))\n",
    "x = Dense(350, name='w2v_embedding_cbow')(inp)\n",
    "x = Average(200)(x)\n",
    "x = Dense(vocabulary_size, activation='softmax')(x)\n",
    "\n",
    "model_cbow = Model(inputs=inp, outputs=x)\n",
    "model_cbow.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6990626",
   "metadata": {},
   "source": [
    "### Fitting the CBOW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6a971e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 04:07:23.395508: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-25 04:07:23.403380: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "   13/31514 [..............................] - ETA: 2:13 - loss: 6.9983 - accuracy: 0.0115       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 04:07:23.703613: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31514/31514 [==============================] - 118s 4ms/step - loss: 6.4640 - accuracy: 0.0453\n",
      "Epoch 2/30\n",
      "31514/31514 [==============================] - 119s 4ms/step - loss: 6.1325 - accuracy: 0.0657\n",
      "Epoch 3/30\n",
      "31514/31514 [==============================] - 115s 4ms/step - loss: 5.9549 - accuracy: 0.0769\n",
      "Epoch 4/30\n",
      "31514/31514 [==============================] - 116s 4ms/step - loss: 5.8414 - accuracy: 0.0846\n",
      "Epoch 5/30\n",
      "31514/31514 [==============================] - 117s 4ms/step - loss: 5.7578 - accuracy: 0.0893\n",
      "Epoch 6/30\n",
      "31514/31514 [==============================] - 120s 4ms/step - loss: 5.6891 - accuracy: 0.0932\n",
      "Epoch 7/30\n",
      "31514/31514 [==============================] - 118s 4ms/step - loss: 5.6295 - accuracy: 0.0961\n",
      "Epoch 8/30\n",
      "31514/31514 [==============================] - 117s 4ms/step - loss: 5.5768 - accuracy: 0.0986\n",
      "Epoch 9/30\n",
      "31514/31514 [==============================] - 115s 4ms/step - loss: 5.5297 - accuracy: 0.1009\n",
      "Epoch 10/30\n",
      "31514/31514 [==============================] - 116s 4ms/step - loss: 5.4870 - accuracy: 0.1025\n",
      "Epoch 11/30\n",
      "31514/31514 [==============================] - 119s 4ms/step - loss: 5.4487 - accuracy: 0.1045\n",
      "Epoch 12/30\n",
      "31514/31514 [==============================] - 117s 4ms/step - loss: 5.4134 - accuracy: 0.1060\n",
      "Epoch 13/30\n",
      "31514/31514 [==============================] - 114s 4ms/step - loss: 5.3820 - accuracy: 0.1074\n",
      "Epoch 14/30\n",
      "31514/31514 [==============================] - 115s 4ms/step - loss: 5.3537 - accuracy: 0.1085\n",
      "Epoch 15/30\n",
      "31514/31514 [==============================] - 115s 4ms/step - loss: 5.3275 - accuracy: 0.1100\n",
      "Epoch 16/30\n",
      "31514/31514 [==============================] - 117s 4ms/step - loss: 5.3040 - accuracy: 0.1109\n",
      "Epoch 17/30\n",
      "31514/31514 [==============================] - 120s 4ms/step - loss: 5.2831 - accuracy: 0.1121\n",
      "Epoch 18/30\n",
      "31514/31514 [==============================] - 120s 4ms/step - loss: 5.2643 - accuracy: 0.1129\n",
      "Epoch 19/30\n",
      "31514/31514 [==============================] - 126s 4ms/step - loss: 5.2475 - accuracy: 0.1136\n",
      "Epoch 20/30\n",
      "31514/31514 [==============================] - 119s 4ms/step - loss: 5.2323 - accuracy: 0.1146\n",
      "Epoch 21/30\n",
      "31514/31514 [==============================] - 120s 4ms/step - loss: 5.2191 - accuracy: 0.1150\n",
      "Epoch 22/30\n",
      "31514/31514 [==============================] - 120s 4ms/step - loss: 5.2074 - accuracy: 0.1161\n",
      "Epoch 23/30\n",
      "31514/31514 [==============================] - 119s 4ms/step - loss: 5.1967 - accuracy: 0.1159\n",
      "Epoch 24/30\n",
      "31514/31514 [==============================] - 120s 4ms/step - loss: 5.1873 - accuracy: 0.1167\n",
      "Epoch 25/30\n",
      "31514/31514 [==============================] - 119s 4ms/step - loss: 5.1791 - accuracy: 0.1173\n",
      "Epoch 26/30\n",
      "31514/31514 [==============================] - 119s 4ms/step - loss: 5.1718 - accuracy: 0.1174\n",
      "Epoch 27/30\n",
      "31514/31514 [==============================] - 119s 4ms/step - loss: 5.1656 - accuracy: 0.1181\n",
      "Epoch 28/30\n",
      "31514/31514 [==============================] - 121s 4ms/step - loss: 5.1598 - accuracy: 0.1179\n",
      "Epoch 29/30\n",
      "31514/31514 [==============================] - 120s 4ms/step - loss: 5.1547 - accuracy: 0.1183\n",
      "Epoch 30/30\n",
      "31514/31514 [==============================] - 120s 4ms/step - loss: 5.1505 - accuracy: 0.1186\n"
     ]
    }
   ],
   "source": [
    "def custom_loss_function(y_true, y_pred):\n",
    "    return tf.reduce_mean(-tf.math.reduce_sum(y_true * tf.math.log(y_pred), axis=[1]))\n",
    "\n",
    "\n",
    "training_started = datetime.datetime.now()\n",
    "model_cbow.compile(loss=custom_loss_function, optimizer=tf.optimizers.SGD(learning_rate=0.9), metrics=['accuracy'])\n",
    "history_cbow = model_cbow.fit(Train_contexts, Train_target, epochs = 30, batch_size=20, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ac711ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_end = datetime.datetime.now()\n",
    "data_info_cbow['training time'] =  training_end - training_started\n",
    "data_info_cbow['cbow model training history'] = history_cbow.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f5237b",
   "metadata": {},
   "source": [
    "### Saving CBOW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b33e8ab8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 05:07:34.905109: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: save/model_cbow/model/2021-11-25_04-07-01-233742/assets\n"
     ]
    }
   ],
   "source": [
    "save_model('cbow', model_cbow, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1439e276",
   "metadata": {},
   "source": [
    "### Testing CBOW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "72b76ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 05:07:39.436320: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4924/4924 - 12s - loss: 6.1195 - accuracy: 0.0863\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_cbow.evaluate(Test_contexts, Test_target, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1529378b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated loss 6.11945104598999 and accuracy 0.08632518351078033\n"
     ]
    }
   ],
   "source": [
    "data_info_cbow['cbow model evaluatation loss'] = loss\n",
    "data_info_cbow['cbow model evaluatation accuracy'] = accuracy\n",
    "print('Evaluated loss',loss, 'and accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f931e73",
   "metadata": {},
   "source": [
    "### Saving Information for CBOW Model\n",
    "\n",
    "For Visualization, pleae upload the vector and metadata from `save/model_cbow/vector_metadata` to https://projector.tensorflow.org "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b359bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_info('cbow',file_name, data_info_cbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "217cf891",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_cbow = model_cbow.get_layer('w2v_embedding_cbow').get_weights()[0]\n",
    "\n",
    "path_cbow = get_path_name('cbow') + 'vector_metadata/'\n",
    "\n",
    "\n",
    "if not os.path.exists(path_cbow):\n",
    "        os.makedirs(path_cbow)\n",
    "\n",
    "out_v = io.open(path_cbow+file_name+'vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open(path_cbow+file_name+'metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index in range(1, vocabulary_size):\n",
    "    vec = weights_cbow[index]\n",
    "    out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "    out_m.write(id_to_word[index] + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "542756c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End of CBOW model!\n"
     ]
    }
   ],
   "source": [
    "print('End of CBOW model!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1c72495f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del accuracy                   \n",
    "del custom_loss_function       \n",
    "del data_info_cbow            \n",
    "del history_cbow              \n",
    "del index                      \n",
    "del inp                       \n",
    "del model_cbow                 \n",
    "del out_m                      \n",
    "del out_v                     \n",
    "del path_cbow                  \n",
    "del train_test_split          \n",
    "del training_end              \n",
    "del training_started           \n",
    "del vec                        \n",
    "del weights_cbow               \n",
    "del words_in_current_sentece   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4db2008",
   "metadata": {},
   "source": [
    "## SKIP-GRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "285a5170",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info_skip = data_info.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9a63d3f",
   "metadata": {},
   "source": [
    "### Creating SKIP-GRAMS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5a0a285d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 1102)]            0         \n",
      "_________________________________________________________________\n",
      "w2v_embedding_skip (Dense)   (None, 500)               551500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1102)              552102    \n",
      "=================================================================\n",
      "Total params: 1,103,602\n",
      "Trainable params: 1,103,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(vocabulary_size, ))\n",
    "x = Dense(500, name='w2v_embedding_skip', bias_initializer=tf.initializers.RandomNormal(stddev=1.0))(inp)\n",
    "x = Dense(vocabulary_size, bias_initializer=tf.initializers.RandomNormal(stddev=1.0), activation='softmax')(x)\n",
    "model_skip = Model(inputs=inp, outputs=x)\n",
    "model_skip.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8464c747",
   "metadata": {},
   "source": [
    "### Fitting Skip-Grams Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b954ae74",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_started = datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d4cf462b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 05:25:35.016236: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15757/15757 [==============================] - 66s 4ms/step - loss: 50.7874 - accuracy: 0.1567\n",
      "Epoch 2/3\n",
      "15757/15757 [==============================] - 66s 4ms/step - loss: 50.6644 - accuracy: 0.1662\n",
      "Epoch 3/3\n",
      "15757/15757 [==============================] - 67s 4ms/step - loss: 50.5595 - accuracy: 0.1710\n"
     ]
    }
   ],
   "source": [
    "def custom_loss_function(y_true, y_pred):\n",
    "    return tf.reduce_mean(-tf.math.reduce_sum(y_true * tf.math.log(y_pred), axis=[1]))\n",
    "\n",
    "\n",
    "model_skip.compile(loss=custom_loss_function, optimizer=tf.optimizers.SGD(learning_rate=0.01), metrics=['accuracy'])\n",
    "history_skip = model_skip.fit(Train_target, Train_contexts, epochs = 3, batch_size=40, verbose=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b76fbef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_end = datetime.datetime.now()\n",
    "data_info_skip['training time'] =  training_end - training_started\n",
    "data_info_skip['skip-grams model training history'] = history_skip.history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddba413c",
   "metadata": {},
   "source": [
    "### Saving SKIP_GRAM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b192848a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model('skip', model_skip, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753e86d1",
   "metadata": {},
   "source": [
    "### Testing SKIP_GRAM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2cc896b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-25 05:36:20.518709: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4924/4924 - 12s - loss: 50.4838 - accuracy: 0.1712\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_skip.evaluate(Test_target, Test_contexts, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "af99f4e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated loss 50.483829498291016 and accuracy 0.17124779522418976\n"
     ]
    }
   ],
   "source": [
    "data_info_skip['skip model evaluatation loss'] = loss\n",
    "data_info_skip['skip model evaluatation accuracy'] = accuracy\n",
    "print('Evaluated loss',loss, 'and accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cfc45cf",
   "metadata": {},
   "source": [
    "### Saving Information for Skip-Gram Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6674ce80",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_info('skip',file_name, data_info_skip)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71849642",
   "metadata": {},
   "source": [
    "### Saving Vector and Metadata For SKIP-GRAM\n",
    "For Visualization, pleae upload the vector and metadata from `save/model_skip/vector_metadata` to https://projector.tensorflow.org "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "af4d0aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_skip = model_skip.get_layer('w2v_embedding_skip').get_weights()[0]\n",
    "\n",
    "path_skip = get_path_name('skip') + 'vector_metadata/'\n",
    "\n",
    "\n",
    "if not os.path.exists(path_skip):\n",
    "        os.makedirs(path_skip)\n",
    "\n",
    "out_v = io.open(path_skip+file_name+'vectors.tsv', 'w', encoding='utf-8')\n",
    "out_m = io.open(path_skip+file_name+'metadata.tsv', 'w', encoding='utf-8')\n",
    "\n",
    "for index in range(1, vocabulary_size):\n",
    "    vec = weights_skip[index]\n",
    "    out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
    "    out_m.write(id_to_word[index] + \"\\n\")\n",
    "out_v.close()\n",
    "out_m.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bda45f0",
   "metadata": {},
   "source": [
    "### Screenshots after Visualizing \n",
    "Visualization link https://projector.tensorflow.org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec61313",
   "metadata": {},
   "source": [
    "<!-- ![title](\"Screenshot_SKIP-GRAM.png\") -->\n",
    "<img src=\"Screenshot_SKIP-GRAM.png\" width=1251 height=910 />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e15f0ef1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End Skip-Gram Model\n"
     ]
    }
   ],
   "source": [
    "print('End Skip-Gram Model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad6c755",
   "metadata": {},
   "source": [
    "# Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773814e5",
   "metadata": {},
   "source": [
    "### CBOW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0450cbc5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 1102)]            0         \n",
      "_________________________________________________________________\n",
      "w2v_embedding_cbow (Dense)   (None, 350)               386050    \n",
      "_________________________________________________________________\n",
      "average (Average)            (None, 350)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1102)              386802    \n",
      "=================================================================\n",
      "Total params: 772,852\n",
      "Trainable params: 772,852\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "cbow = load_model('cbow', file_name)\n",
    "print(cbow.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "531ab5cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_limit': 3000,\n",
       " 'min_frquency_of_word': 300,\n",
       " 'window_size': 7,\n",
       " 'max_sentence_lenght': 1000,\n",
       " 'max_word_count': 100,\n",
       " 'min_word_count': 5,\n",
       " 'max_sentence': 1000,\n",
       " 'Total sentences before filtering': 135022,\n",
       " 'Total words before filtering': 1762061,\n",
       " 'Total sentences after filtering': 91451,\n",
       " 'Total words after filtering': 787833,\n",
       " 'Total unique words in dictionary': 1102,\n",
       " 'Total target words': 787833,\n",
       " 'training time': datetime.timedelta(seconds=3614, microseconds=813276),\n",
       " 'cbow model training history': {'loss': [6.4640021324157715,\n",
       "   6.132530689239502,\n",
       "   5.954929828643799,\n",
       "   5.841360092163086,\n",
       "   5.757752895355225,\n",
       "   5.689090251922607,\n",
       "   5.6295294761657715,\n",
       "   5.576821804046631,\n",
       "   5.529684543609619,\n",
       "   5.486954689025879,\n",
       "   5.448729515075684,\n",
       "   5.413358211517334,\n",
       "   5.3820481300354,\n",
       "   5.353657245635986,\n",
       "   5.327454090118408,\n",
       "   5.304045677185059,\n",
       "   5.283064842224121,\n",
       "   5.2642951011657715,\n",
       "   5.2475481033325195,\n",
       "   5.232334613800049,\n",
       "   5.219137668609619,\n",
       "   5.207401275634766,\n",
       "   5.19665002822876,\n",
       "   5.187325954437256,\n",
       "   5.1791300773620605,\n",
       "   5.171757698059082,\n",
       "   5.165648460388184,\n",
       "   5.159820079803467,\n",
       "   5.154742240905762,\n",
       "   5.150454998016357],\n",
       "  'accuracy': [0.0453205481171608,\n",
       "   0.06571828573942184,\n",
       "   0.07688182592391968,\n",
       "   0.08455001562833786,\n",
       "   0.08930198103189468,\n",
       "   0.0931527316570282,\n",
       "   0.09611021727323532,\n",
       "   0.09859329462051392,\n",
       "   0.10090342909097672,\n",
       "   0.1024995818734169,\n",
       "   0.10452094674110413,\n",
       "   0.10597747564315796,\n",
       "   0.10739433765411377,\n",
       "   0.10851132869720459,\n",
       "   0.10998689383268356,\n",
       "   0.11089286208152771,\n",
       "   0.11213519424200058,\n",
       "   0.11287615448236465,\n",
       "   0.11360283195972443,\n",
       "   0.11462779343128204,\n",
       "   0.11504983901977539,\n",
       "   0.11605417728424072,\n",
       "   0.11588599532842636,\n",
       "   0.11670628190040588,\n",
       "   0.11730444431304932,\n",
       "   0.11741708964109421,\n",
       "   0.1180914118885994,\n",
       "   0.11786769330501556,\n",
       "   0.11826911568641663,\n",
       "   0.11856105178594589]},\n",
       " 'cbow model evaluatation loss': 6.11945104598999,\n",
       " 'cbow model evaluatation accuracy': 0.08632518351078033}"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_info('cbow', file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ae11c3",
   "metadata": {},
   "source": [
    "### Skip-Gram Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "19878f7b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 1102)]            0         \n",
      "_________________________________________________________________\n",
      "w2v_embedding_skip (Dense)   (None, 500)               551500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1102)              552102    \n",
      "=================================================================\n",
      "Total params: 1,103,602\n",
      "Trainable params: 1,103,602\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "skip = load_model('skip', file_name)\n",
    "print(skip.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0facc9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_limit': 3000,\n",
       " 'min_frquency_of_word': 300,\n",
       " 'window_size': 7,\n",
       " 'max_sentence_lenght': 1000,\n",
       " 'max_word_count': 100,\n",
       " 'min_word_count': 5,\n",
       " 'max_sentence': 1000,\n",
       " 'Total sentences before filtering': 135022,\n",
       " 'Total words before filtering': 1762061,\n",
       " 'Total sentences after filtering': 91451,\n",
       " 'Total words after filtering': 787833,\n",
       " 'Total unique words in dictionary': 1102,\n",
       " 'Total target words': 787833,\n",
       " 'training time': datetime.timedelta(seconds=646, microseconds=75382),\n",
       " 'skip-grams model training history': {'loss': [50.78736877441406,\n",
       "   50.66439437866211,\n",
       "   50.55951690673828],\n",
       "  'accuracy': [0.15667036175727844, 0.16623298823833466, 0.17100399732589722]},\n",
       " 'skip model evaluatation loss': 50.483829498291016,\n",
       " 'skip model evaluatation accuracy': 0.17124779522418976}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_info('skip', file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "988dba57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE END\n"
     ]
    }
   ],
   "source": [
    "print('THE END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f764c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflowEnv] *",
   "language": "python",
   "name": "conda-env-tensorflowEnv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
